{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AeT9xauVJw1",
        "outputId": "6ed263b2-a98d-427d-b88a-ac55f7769ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/2]: 100%|██████████| 469/469 [13:03<00:00,  1.67s/it, loss=0.00062]\n",
            "Epoch [2/2]: 100%|██████████| 469/469 [12:41<00:00,  1.62s/it, loss=0.000806]\n",
            "Epoch [1/2]: 100%|██████████| 469/469 [04:46<00:00,  1.64it/s]\n",
            "Epoch [2/2]: 100%|██████████| 469/469 [04:46<00:00,  1.64it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定義DIP模型\n",
        "class DIP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DIP, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.relu(self.conv4(x))\n",
        "        x = self.relu(self.conv5(x))\n",
        "        x = self.conv6(x)\n",
        "        return x\n",
        "\n",
        "# 定義DDPM模型\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(self, T, beta_start=0.0001, beta_end=0.02):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.T = T\n",
        "        self.beta = torch.linspace(beta_start, beta_end, T)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, 0)\n",
        "\n",
        "    def forward(self, x0):\n",
        "        t = torch.randint(0, self.T, (x0.size(0),), device=x0.device)\n",
        "        epsilon = torch.randn_like(x0)\n",
        "        xt = torch.sqrt(self.alpha_hat[t]).unsqueeze(1).unsqueeze(2).unsqueeze(3) * x0 + \\\n",
        "             torch.sqrt(1 - self.alpha_hat[t]).unsqueeze(1).unsqueeze(2).unsqueeze(3) * epsilon\n",
        "        return xt\n",
        "\n",
        "# 加載數據\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# 訓練DIP模型\n",
        "def train_DIP(dip_model, dataloader, epochs=2, lr=0.001):\n",
        "    optimizer = optim.Adam(dip_model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    for epoch in range(epochs):\n",
        "        progress_bar = tqdm(dataloader, desc=f'Epoch [{epoch+1}/{epochs}]')\n",
        "        for data in progress_bar:\n",
        "            img, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            output = dip_model(img)\n",
        "            loss = criterion(output, img)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "        save_image(output, f'output_DIP_epoch{epoch+1}.png')\n",
        "    return dip_model\n",
        "\n",
        "# 使用DIP模型輸出作為DDPM初始先驗\n",
        "def train_DDPM(ddpm_model, dip_model, dataloader, epochs=2):\n",
        "    for epoch in range(epochs):\n",
        "        progress_bar = tqdm(dataloader, desc=f'Epoch [{epoch+1}/{epochs}]')\n",
        "        for data in progress_bar:\n",
        "            img, _ = data\n",
        "            dip_output = dip_model(img).detach()\n",
        "            ddpm_output = ddpm_model(dip_output)\n",
        "            progress_bar.update(1)\n",
        "            if (epoch + 1) % 1 == 0:\n",
        "                save_image(ddpm_output, f'output_DDPM_epoch{epoch+1}.png')\n",
        "\n",
        "# 初始化模型並進行訓練\n",
        "dip_model = DIP()\n",
        "ddpm_model = DDPM(T=500)\n",
        "\n",
        "# 訓練DIP模型\n",
        "dip_model = train_DIP(dip_model, dataloader, epochs=2)\n",
        "\n",
        "# 使用DIP模型的輸出作為DDPM初始先驗進行訓練\n",
        "train_DDPM(ddpm_model, dip_model, dataloader, epochs=2)\n"
      ]
    }
  ]
}